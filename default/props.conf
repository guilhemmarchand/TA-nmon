# props.conf

##################################
#			nmon2csv stanza			#
##################################

# IMPORTANT: Since the V1.6.0, the configuration uses the nmon2csv.sh wrapper that will call nmon2csv.py (prefered choice) or nmon2csv.pl if appropriated
# You can still force the configuration to use the Python or Perl converter (but the nmon2csv.sh wrapper will do the choice for you, enforcing the choice is not required anymore)

# *** BE UPGRADE RESILIENT: *** Copy this stanza to your local/props.conf to prevent futur upgrades from overwritting your setting 

# To force the use of the Python converter, set:
# unarchive_cmd = $SPLUNK_HOME/etc/apps/TA-nmon/bin/nmon2csv.py

# To force the use of the Python converter, set:
# unarchive_cmd = $SPLUNK_HOME/etc/apps/TA-nmon/bin/nmon2csv.pl

# This source stanza will be called by the archive processor to convert NMON raw data into csv files
# Splunk can manage. See inputs.conf for the associated monitor

# To force nmon2csv parsers to always consider nmon files as realtime data, you can set the option "--mode realtime":
# unarchive_cmd = $SPLUNK_HOME/etc/apps/TA-nmon/bin/nmon2csv.sh --mode realtime
# This is normally not necessary as parsers will automatically detect if we are dealing with realtime data

# host name definition: by default, nmon2csv parsers will use the value returned by nmon for the host name definition. (available in the config section - AAA,host)
# If you want to have hosts using their fully qualified domain name (fqdn) instead of the nmon hostname value, add the option "--use_fqdn" in the source stanza definition
# the value of host name will be equivalent to the "hostname -f" command on the host.
# **CAUTION**: Do use this option when managing nmon data generated out of Splunk (central repositories) or all the data being ingested will be identified as coming the host
# that managed the nmon data
# This option must be used on host that are only managing their own nmon data.

# To activate fqdn:
# unarchive_cmd = $SPLUNK_HOME/bin/splunk cmd $SPLUNK_HOME/etc/apps/nmon/bin/nmon2csv.sh --use_fqdn

[source::.../*.nmon]
invalid_cause = archive
unarchive_cmd = $SPLUNK_HOME/etc/apps/TA-nmon/bin/nmon2csv.sh --mode realtime
sourcetype = nmon_processing
NO_BINARY_CHECK = true

# To manage repositories archives of cold nmon files (add you own for other compressed formats)
[source::.../*.nmon.gz]
invalid_cause = archive
unarchive_cmd = gunzip | $SPLUNK_HOME/etc/apps/TA-nmon/bin/nmon2csv.sh
sourcetype = nmon_processing
NO_BINARY_CHECK = true

###########################################
#			nmon converted csv stanza			#
###########################################

# This sourcetype stanza will be used to index nmon csv converted data
# Every generated csv file will contain a CSV header used by Splunk to identify fields

[nmon_data]

FIELD_DELIMITER=,
FIELD_QUOTE="
HEADER_FIELD_LINE_NUMBER=1

# your settings
INDEXED_EXTRACTIONS=csv
NO_BINARY_CHECK=1
SHOULD_LINEMERGE=false
TIMESTAMP_FIELDS=ZZZZ
TIME_FORMAT=%d-%m-%Y %H:%M:%S

# set by detected source type
KV_MODE=none
pulldown_type=true

# Leaving PUNCT enabled can impact indexing performance, and uses space
# For structured data, it has poor interest and shall be deactivated
ANNOTATE_PUNCT=false

# Overwritting default host field based on event data for nmon_data sourcetype (useful when managing Nmon central shares)
TRANSFORMS-hostfield=nmon_data_hostoverride

###########################################
#			nmon processing stanza				#
###########################################

[nmon_processing]

TIME_FORMAT=%d-%m-%Y %H:%M:%S

###########################################
#			nmon config stanza					#
###########################################

[nmon_config]

BREAK_ONLY_BEFORE=CONFIG,
MAX_EVENTS=100000
NO_BINARY_CHECK=1
SHOULD_LINEMERGE=true
TIME_FORMAT=%d-%b-%Y:%H:%M
TIME_PREFIX=CONFIG,
TRUNCATE=0

# Overwritting default host field based on event data for nmon_data sourcetype (useful when managing Nmon central shares)
TRANSFORMS-hostfield=nmon_config_hostoverride

##############################################
#			SYSLOG SPECIAL SECTIONS					#
##############################################

# These parameters are dedicated to the deployment of Nmon using syslog as the transport layer
# to forward Nmon Performance data from your end servers to your central syslog, and finally to Splunk

# Deploying Nmon with syslog requires additional configuration on search heads, and potentially indexers
# This also requires specific configuration on end clients (rsyslog/syslog-ng config, cron config, logrotate)

# Data being transferred through syslog is not csv structured data but key=value data
# each source of data is being in a temporary sourcetype for indexing time parsing to occur, then we will
# rewrite the sourcetypes to match standard sourcetypes being used by Core application

# depending on its origin (the source, normal vs syslog), the configuration on the sh head will apply the correct
# extraction parameters at search time.

# The nmon-logger package for Syslog deployment is available at:
# https://github.com/guilhemmarchand/nmon-logger

# Online guides for Syslog deployment:
# rsyslog: http://nmonsplunk.wikidot.com/documentation:installation:rsyslog
# syslog-ng: http://nmonsplunk.wikidot.com/documentation:installation:syslog-ng

####################
# Syslog to Splunk #
####################
#
# If you receive directly from syslog over TCP/UDP, use this sourcetype
# Create a dedicated UDP or TCP input with:
# index = nmon
# source = (leave optional or put anything you like)
# sourcetype = nmon:fromsyslog

# This sourcetype must manage incoming multi / or mono line event
# syslog timestamp is not being used for data time stamping (using nmon timestamp)

#
# Splunk to Splunk is not recommended, prefer having a Splunk instance installed on rsyslog collectors
# or on machine receiving rsyslog data, and generating local per host files
# Therefore, it is still possible to achieve it using a tcp/udp input using this sourcetype:

[nmon:fromsyslog]

BREAK_ONLY_BEFORE=timestamp="
MAX_EVENTS=100000
SHOULD_LINEMERGE=true
NO_BINARY_CHECK=true
CHARSET=UTF-8
TIME_FORMAT=%s
TIME_PREFIX=timestamp="
MAX_TIMESTAMP_LOOKAHEAD=26

# Manage carriage returns sent by syslog
SEDCMD-carriage_return2 = s/#012/\n/g

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS = syslog-host

# Rewrite sourcetype to standard nmon_data
TRANSFORMS-perfdata_fromsyslog = nmon_data_fromsyslog_rewrite

# Rewrite sourcetype to standard nmon_config
TRANSFORMS-configdata_fromsyslog = nmon_config_fromsyslog_rewrite

# Rewrite sourcetype to standard nmon_processing
TRANSFORMS-processingdata_fromsyslog = nmon_processing_fromsyslog_rewrite

# Rewrite sourcetype to standard nmon_collect
TRANSFORMS-collectdata_fromsyslog = nmon_collect_fromsyslog_rewrite

# Rewrite sourcetype to standard nmon_clean
TRANSFORMS-cleandata_fromsyslog = nmon_clean_fromsyslog_rewrite

#####################################
# Splunk to Splunk with syslog data #
#####################################

# These sourcetypes will be used when reading local files generated by syslog from remote syslog clients
# Each type of data must have its own file monitor.

# See inputs.conf.spec for more information, or read the online wiki manual pages for rsyslog / syslog-ng deployments

#
# For nmon performance data:
#

###################################################
# Set parameters for nmon_data coming from syslog #
###################################################

[nmon_data:fromsyslog]
SHOULD_LINEMERGE=false
NO_BINARY_CHECK=true
CHARSET=UTF-8
TIME_FORMAT=%s
TIME_PREFIX=timestamp="
MAX_TIMESTAMP_LOOKAHEAD=26
KV_MODE=auto

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS = syslog-host

# Rewrite sourcetype to standard nmon_data
TRANSFORMS-perfdata_fromsyslog = nmon_data_fromsyslog_rewrite

# For search heads, activate kvmode to auto for that source
[source::perfdata:syslog]
KV_MODE=auto

#
# For nmon configuration data:
#

#####################################################
# Set parameters for nmon_config coming from syslog #
#####################################################

[nmon_config:fromsyslog]
BREAK_ONLY_BEFORE=timestamp="
MAX_EVENTS=100000
NO_BINARY_CHECK=1
SHOULD_LINEMERGE=true
TIME_FORMAT=%s
TIME_PREFIX=timestamp="
TRUNCATE=0

# Manage carriage returns sent by syslog
SEDCMD-carriage_return2 = s/#012/\n/g

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS = syslog-host

# Rewrite sourcetype to standard nmon_config
TRANSFORMS-configdata_fromsyslog = nmon_config_fromsyslog_rewrite

#
# For nmon processing data:
#

[nmon_processing:fromsyslog]
SHOULD_LINEMERGE=true
NO_BINARY_CHECK=true
TIME_FORMAT=%d-%m-%Y %H:%M:%S
TIME_PREFIX=nmon2csv:
CHARSET=UTF-8
BREAK_ONLY_BEFORE=nmon2csv:

# Manage carriage returns sent by syslog
SEDCMD-carriage_return2 = s/#012/\n/g

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS = syslog-host

# Rewrite sourcetype to standard nmon_processing
TRANSFORMS-processingdata_fromsyslog = nmon_processing_fromsyslog_rewrite

#
# For nmon collecting data:
#

[nmon_collect:fromsyslog]

# Manage carriage returns sent by syslog
SEDCMD-carriage_return2 = s/#012/\n/g

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS = syslog-host

# Rewrite sourcetype to standard nmon_collect
TRANSFORMS-collectdata_fromsyslog = nmon_collect_fromsyslog_rewrite

#
# For nmon clean data:
#

[nmon_clean:fromsyslog]
SHOULD_LINEMERGE=true
NO_BINARY_CHECK=true
BREAK_ONLY_BEFORE=Starting nmon cleaning
TIME_FORMAT=%c
TIME_PREFIX=\w*\s
CHARSET=UTF-8

# Manage carriage returns sent by syslog
SEDCMD-carriage_return2 = s/#012/\n/g

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS = syslog-host

# Rewrite sourcetype to standard nmon_clean
TRANSFORMS-cleandata_fromsyslog = nmon_clean_fromsyslog_rewrite
